{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import random\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from myStopwords import stopword\n",
    "from clean_file import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lilin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lilin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\lilin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import emoji\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text\n",
    "\n",
    "def remove_digits(text):\n",
    "    text = ''.join([digit for digit in text if not digit.isdigit()])\n",
    "    return text\n",
    "\n",
    "def remove_emojis(text):\n",
    "    text = re.sub(emoji.get_emoji_regexp(), r\"\", text)\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = ' '.join(word for word in text.split() if word not in stopword)\n",
    "    return text\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.replace(\"&#39;\", \"'\")\n",
    "    text = text.replace(\"&quot;\", \"\")\n",
    "    text = text.replace(\"&amp;\", \"\")\n",
    "    text = text.replace(\"‘\", \"'\")\n",
    "    text = text.replace(\"’\", \"'\")\n",
    "    text = text.replace(\"“\", \"'\")\n",
    "    text = text.replace(\"”\", \"'\")\n",
    "    text = text.replace(\" – \", \" \")\n",
    "    text = text.replace(\"—\", \" \")\n",
    "    text = text.replace(\"•\", \" \")\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'bit.ly/\\S+', '', text)\n",
    "    text = re.sub('(RT\\s@[A-Za-z0-9-_]+[A-Za-z0-9-_]: +)', '', text)\n",
    "    text = re.sub('(@[A-Za-z0-9-_]+[A-Za-z0-9-_]+)', '', text)\n",
    "    text = BeautifulSoup(text, \"lxml\").text \n",
    "    text = text.lower()\n",
    "    text = remove_punctuations(text)\n",
    "    text = remove_digits(text)\n",
    "    text = remove_emojis(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = lemmatize_text(text)\n",
    "    return text\n",
    "\n",
    "def nltk2wn_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "    \n",
    "def lemmatize_text(text):\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(text))  \n",
    "    wn_tagged = map(lambda x: (x[0], nltk2wn_tag(x[1])), nltk_tagged)\n",
    "    res_words = []\n",
    "    for word, tag in wn_tagged:\n",
    "        if tag is None:            \n",
    "            res_words.append(word)\n",
    "        else:\n",
    "            res_words.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(res_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('training_1.xlsx')\n",
    "df = df[['text', 'label']]\n",
    "df.columns = ['text', 'label']\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df.loc[df['label'] != 0]\n",
    "dff['clean_text'] = dff['text'].apply(clean_text)\n",
    "dff = dff.dropna(subset= ['clean_text'])\n",
    "dff.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['1', '-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "dff['label'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19504\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>reopen res publica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>reopen country</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>country</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>country reopen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>reopen nation country</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text  label\n",
       "0     reopen res publica      1\n",
       "1         reopen country      1\n",
       "2                country      1\n",
       "3         country reopen      1\n",
       "4  reopen nation country      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_excel('training_2.xlsx')\n",
    "print(len(df1))\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume before filter 19504\n"
     ]
    }
   ],
   "source": [
    "def filter_text(text):\n",
    "    return None if len(text.split()) < 2 else text\n",
    "\n",
    "print('volume before filter', len(df1))\n",
    "#df1['text'] = df1['text'].apply(filter_text)\n",
    "#df1 = df1.dropna(subset=['text'])\n",
    "#print('volume after filter', len(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RT @TheDemocrats: We can’t know when it’s safe...</td>\n",
       "      <td>-1</td>\n",
       "      <td>cant know safe reopen widespread testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RT @CBSNews: Dr. Fauci on guidelines to reopen...</td>\n",
       "      <td>-1</td>\n",
       "      <td>dr fauci guideline reopen us economy program n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RT @thehill: Seattle Mayor says she does not b...</td>\n",
       "      <td>-1</td>\n",
       "      <td>seattle mayor say not believe city state ameri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RT @JohnCornyn: Opinion: We can gradually reop...</td>\n",
       "      <td>1</td>\n",
       "      <td>opinion gradually reopen texan part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RT @dougducey: Thank you @POTUS &amp;amp; @SecBern...</td>\n",
       "      <td>1</td>\n",
       "      <td>thank work reopen americas national park az pl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  RT @TheDemocrats: We can’t know when it’s safe...     -1   \n",
       "1  RT @CBSNews: Dr. Fauci on guidelines to reopen...     -1   \n",
       "2  RT @thehill: Seattle Mayor says she does not b...     -1   \n",
       "3  RT @JohnCornyn: Opinion: We can gradually reop...      1   \n",
       "4  RT @dougducey: Thank you @POTUS &amp; @SecBern...      1   \n",
       "\n",
       "                                          clean_text  \n",
       "0           cant know safe reopen widespread testing  \n",
       "1  dr fauci guideline reopen us economy program n...  \n",
       "2  seattle mayor say not believe city state ameri...  \n",
       "3                opinion gradually reopen texan part  \n",
       "4  thank work reopen americas national park az pl...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_excel('testing_3.xlsx')\n",
    "df2['clean_text'] = df2['text'].apply(clean_text)\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df1['text']\n",
    "y_train = df1['label']\n",
    "X_test = df2['clean_text']\n",
    "y_test = df2['label']\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Multinomial Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 93.88%\n",
      "test accuracy: 72.81%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.73      0.77      1013\n",
      "          -1       0.63      0.73      0.68       642\n",
      "\n",
      "    accuracy                           0.73      1655\n",
      "   macro avg       0.72      0.73      0.72      1655\n",
      "weighted avg       0.74      0.73      0.73      1655\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_trad = nb.predict(X_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print(\"train accuracy: %.2f%%\" % (accuracy_score(y_trad, y_train)*100))\n",
    "print(\"test accuracy: %.2f%%\" % (accuracy_score(y_pred, y_test)*100))\n",
    "print(classification_report(y_test, y_pred,target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Linear Support Vector with SDG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 93.37%\n",
      "test accuracy: 72.51%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.72      0.76      1013\n",
      "          -1       0.62      0.73      0.67       642\n",
      "\n",
      "    accuracy                           0.73      1655\n",
      "   macro avg       0.72      0.73      0.72      1655\n",
      "weighted avg       0.74      0.73      0.73      1655\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='log', penalty='l2',alpha=1e-4, random_state=45, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "y_trad = sgd.predict(X_train)\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print(\"train accuracy: %.2f%%\" % (accuracy_score(y_trad, y_train)*100))\n",
    "print(\"test accuracy: %.2f%%\" % (accuracy_score(y_pred, y_test)*100))\n",
    "print(classification_report(y_test, y_pred,target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 99.97%\n",
      "test accuracy: 67.85%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.68      0.72      1013\n",
      "          -1       0.57      0.67      0.62       642\n",
      "\n",
      "    accuracy                           0.68      1655\n",
      "   macro avg       0.67      0.68      0.67      1655\n",
      "weighted avg       0.69      0.68      0.68      1655\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(solver='lbfgs', C=1e5, max_iter=3000)),\n",
    "               ])\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_trad = lr.predict(X_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(\"train accuracy: %.2f%%\" % (accuracy_score(y_trad, y_train)*100))\n",
    "print(\"test accuracy: %.2f%%\" % (accuracy_score(y_pred, y_test)*100))\n",
    "print(classification_report(y_test, y_pred,target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def label_data(text, label):\n",
    "    return nb.predict([text])[0] if pd.isnull(label) else label\n",
    "\n",
    "def label_datafile(filepath, dfs):\n",
    "    dft = pd.read_excel(filepath)\n",
    "    dft = clean_file(dft, dfs)\n",
    "    dft = dft.loc[dft['lang']=='en']\n",
    "    df = pd.merge(dft, dfs, on='text', how=\"left\")\n",
    "    df['clean_text'] = df.apply(lambda row: clean_text(str(row['text'])), axis = 1)\n",
    "    df['label'] = df.apply(lambda row: label_data(str(row['clean_text']), row['label']), axis = 1)\n",
    "    df = df[['user', 'verified', 'location', 'state', 'followers', 'time', 'text', 'lang', 'label', 'sentiment',\n",
    "             'rt_user', 'rt_verified', 'rt_location', 'rt_followers', 'rt_time', 'rt_lang']]\n",
    "    filename = str(filepath).split('\\\\')[-1].split('_sentiment')[0] + '_label.xlsx'\n",
    "    write_excel(df, filename, save_directory)\n",
    "    print('-------- finish writing file:', filename, '--------')\n",
    "        \n",
    "def write_excel(df, filename, save_directory):\n",
    "    directory = save_directory + '/'\n",
    "    os.makedirs(os.path.dirname(directory), exist_ok=True)\n",
    "    output_file = os.path.join(directory, filename)      \n",
    "    writer = pd.ExcelWriter(output_file, engine='xlsxwriter', options={'strings_to_urls': False})\n",
    "    df.to_excel(writer, index=False)\n",
    "    writer.save()\n",
    "    \n",
    "def read_folder(read_directory):\n",
    "    files = glob.glob(read_directory + \"/*.xlsx\")\n",
    "    for file in files:\n",
    "        label_datafile(file, dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RT @lydiathegreat_: So Texas has closed school...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RT @realDonaldTrump: REOPEN OUR COUNTRY!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RT @keithedwards: America getting ready to reo...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RT @miaxmon: new zealand were fast to act and ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RT @realDonaldTrump: Many States moving to SAF...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  RT @lydiathegreat_: So Texas has closed school...     -1\n",
       "1           RT @realDonaldTrump: REOPEN OUR COUNTRY!      1\n",
       "2  RT @keithedwards: America getting ready to reo...     -1\n",
       "3  RT @miaxmon: new zealand were fast to act and ...     -1\n",
       "4  RT @realDonaldTrump: Many States moving to SAF...      1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = pd.read_excel('samples.xlsx')\n",
    "dfs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------start to clean file-----------\n",
      "the number of tweet before filtering: 132205\n",
      "the number of tweet after removing: 118496\n",
      "the number of tweet after cleaning: 110071\n",
      "the number of tweet after filtering: 95853\n",
      "-------- finish writing file: reopen_2020-04-17_label.xlsx --------\n",
      "----------start to clean file-----------\n",
      "the number of tweet before filtering: 427941\n",
      "the number of tweet after removing: 380576\n",
      "the number of tweet after cleaning: 353238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lilin\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:294: UserWarning: \"b'reopen '\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\lilin\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:294: UserWarning: \"b'REOPEN '\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\lilin\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:294: UserWarning: \"b'Reopen '\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of tweet after filtering: 305343\n",
      "-------- finish writing file: reopen_2020-04-18_to_2020-04-24_label.xlsx --------\n",
      "----------start to clean file-----------\n",
      "the number of tweet before filtering: 165441\n",
      "the number of tweet after removing: 150177\n",
      "the number of tweet after cleaning: 136342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lilin\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:294: UserWarning: \"b'Reopen. '\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of tweet after filtering: 110578\n",
      "-------- finish writing file: reopen_2020-04-25_to_2020-04-28_label.xlsx --------\n",
      "----------start to clean file-----------\n",
      "the number of tweet before filtering: 235624\n",
      "the number of tweet after removing: 221072\n",
      "the number of tweet after cleaning: 192970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lilin\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:294: UserWarning: \"b'Reopen  '\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of tweet after filtering: 156782\n",
      "-------- finish writing file: reopen_2020-04-29_to_2020-05-03_label.xlsx --------\n",
      "----------start to clean file-----------\n",
      "the number of tweet before filtering: 51319\n",
      "the number of tweet after removing: 43357\n",
      "the number of tweet after cleaning: 39282\n",
      "the number of tweet after filtering: 30578\n",
      "-------- finish writing file: reopen_2020-05-04_label.xlsx --------\n",
      "----------start to clean file-----------\n",
      "the number of tweet before filtering: 58847\n",
      "the number of tweet after removing: 50712\n",
      "the number of tweet after cleaning: 46333\n",
      "the number of tweet after filtering: 36218\n",
      "-------- finish writing file: reopen_2020-05-05_label.xlsx --------\n",
      "----------start to clean file-----------\n",
      "the number of tweet before filtering: 66359\n",
      "the number of tweet after removing: 58638\n",
      "the number of tweet after cleaning: 51959\n",
      "the number of tweet after filtering: 40717\n",
      "-------- finish writing file: reopen_2020-05-06_label.xlsx --------\n",
      "----------start to clean file-----------\n",
      "the number of tweet before filtering: 85793\n",
      "the number of tweet after removing: 66733\n",
      "the number of tweet after cleaning: 60087\n",
      "the number of tweet after filtering: 46475\n",
      "-------- finish writing file: reopen_2020-05-07_label.xlsx --------\n",
      "----------start to clean file-----------\n",
      "the number of tweet before filtering: 56748\n",
      "the number of tweet after removing: 50770\n",
      "the number of tweet after cleaning: 44929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lilin\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:294: UserWarning: \"b'Reopen'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of tweet after filtering: 33472\n",
      "-------- finish writing file: reopen_2020-05-08_label.xlsx --------\n",
      "----------start to clean file-----------\n",
      "the number of tweet before filtering: 87290\n",
      "the number of tweet after removing: 78977\n",
      "the number of tweet after cleaning: 73292\n",
      "the number of tweet after filtering: 62286\n",
      "-------- finish writing file: reopen_2020-05-09_to_2020-05-10_label.xlsx --------\n",
      "----------start to clean file-----------\n",
      "the number of tweet before filtering: 147224\n",
      "the number of tweet after removing: 133040\n",
      "the number of tweet after cleaning: 117854\n",
      "the number of tweet after filtering: 92344\n",
      "-------- finish writing file: reopen_2020-05-11_to_2020-05-12_label.xlsx --------\n",
      "----------start to clean file-----------\n",
      "the number of tweet before filtering: 158116\n",
      "the number of tweet after removing: 132077\n",
      "the number of tweet after cleaning: 118770\n",
      "the number of tweet after filtering: 94823\n",
      "-------- finish writing file: reopen_2020-05-13_to_2020-05-14_label.xlsx --------\n",
      "----------start to clean file-----------\n",
      "the number of tweet before filtering: 96265\n",
      "the number of tweet after removing: 78956\n",
      "the number of tweet after cleaning: 70665\n",
      "the number of tweet after filtering: 54788\n",
      "-------- finish writing file: reopen_2020-05-15_to_2020-05-16_label.xlsx --------\n",
      "----------start to clean file-----------\n",
      "the number of tweet before filtering: 137352\n",
      "the number of tweet after removing: 125997\n",
      "the number of tweet after cleaning: 119685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lilin\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:294: UserWarning: \"b'Reopen.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\lilin\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:294: UserWarning: \"b'rEoPeN '\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of tweet after filtering: 104124\n",
      "-------- finish writing file: reopen_2020-05-17_to_2020-05-18_label.xlsx --------\n",
      "----------start to clean file-----------\n",
      "the number of tweet before filtering: 122494\n",
      "the number of tweet after removing: 108242\n",
      "the number of tweet after cleaning: 100434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lilin\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:294: UserWarning: \"b'ReOpEn '\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of tweet after filtering: 80999\n",
      "-------- finish writing file: reopen_2020-05-19_to_2020-05-20_label.xlsx --------\n",
      "----------start to clean file-----------\n",
      "the number of tweet before filtering: 162253\n",
      "the number of tweet after removing: 139496\n",
      "the number of tweet after cleaning: 122591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lilin\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:294: UserWarning: \"b'REOPEN  '\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of tweet after filtering: 96835\n",
      "-------- finish writing file: reopen_2020-05-21_to_2020-05-23_label.xlsx --------\n",
      "----------start to clean file-----------\n",
      "the number of tweet before filtering: 97704\n",
      "the number of tweet after removing: 88289\n",
      "the number of tweet after cleaning: 76751\n",
      "the number of tweet after filtering: 59325\n",
      "-------- finish writing file: reopen_2020-05-24_to_2020-05-26_label.xlsx --------\n",
      "----------start to clean file-----------\n",
      "the number of tweet before filtering: 118936\n",
      "the number of tweet after removing: 105129\n",
      "the number of tweet after cleaning: 95795\n",
      "the number of tweet after filtering: 66558\n",
      "-------- finish writing file: reopen_2020-05-27_to_2020-05-30_label.xlsx --------\n"
     ]
    }
   ],
   "source": [
    "read_directory = \"reopen_clean\"\n",
    "save_directory = \"reopen_final\"\n",
    "read_folder(read_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
